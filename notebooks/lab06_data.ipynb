{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlH0lCOttCs5"
   },
   "source": [
    "<img src=\"https://fsdl.me/logo-720-dark-horizontal\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUPRHaeetRnT"
   },
   "source": [
    "# Lab 06: Data Annotation & Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bry3Hr-PcgDs"
   },
   "source": [
    "### What You Will Learn\n",
    "\n",
    "- How the `IAMParagraphs` dataset is structured\n",
    "- How to use Label Studio to set up a data annotation workflow\n",
    "- Just how messy data really is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vs0LXXlCU6Ix"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkQiK7lkgeXm"
   },
   "source": [
    "If you're running this notebook on Google Colab,\n",
    "the cell below will run full environment setup.\n",
    "\n",
    "It should take about three minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REr0rbW_qb8j"
   },
   "outputs": [],
   "source": [
    "%env FSDL_REPO=fsdl-text-recognizer-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVx7C7H0PIZC"
   },
   "outputs": [],
   "source": [
    "lab_idx = None  # CHANGE ME WHEN YOU COPY THE TEMPLATE OVER\n",
    "\n",
    "\n",
    "if \"bootstrap\" not in locals() or bootstrap.run:\n",
    "    # path management for Python\n",
    "    pythonpath, = !echo $PYTHONPATH\n",
    "    if \".\" not in pythonpath.split(\":\"):\n",
    "        pythonpath = \".:\" + pythonpath\n",
    "        %env PYTHONPATH={pythonpath}\n",
    "        !echo $PYTHONPATH\n",
    "\n",
    "    # get both Colab and local notebooks into the same state\n",
    "    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
    "    import bootstrap\n",
    "\n",
    "    # change into the lab directory\n",
    "    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
    "\n",
    "    # needed for inline plots in some contexts\n",
    "    %matplotlib inline\n",
    "\n",
    "    bootstrap.run = False  # change to True re-run setup\n",
    "    \n",
    "!pwd\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTkKzEMNR8XZ"
   },
   "source": [
    "# `IAMParagraphs`: From annotated data to a PyTorch `Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mQLbjuiwZuj"
   },
   "source": [
    "We've used the `text_recognizer.data` submodule\n",
    "to serve up PyTorch `Dataset`s that our\n",
    "`DataLoader`s and `LightningDataModule`s can\n",
    "turn into PyTorch `Tensor`s ready to train our DNNs.\n",
    "\n",
    "These `Dataset`s operate on a much rawer format of data,\n",
    "which looks much like other kinds of data.\n",
    "\n",
    "Let's walk through their processing in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3438d2e"
   },
   "source": [
    "This class downloads the data --\n",
    "we'll talk more about it later,\n",
    "but we want to have the data present for the first part of the discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18900eec"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam import IAM\n",
    "\n",
    "iam = IAM()\n",
    "iam.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "499c23a6"
   },
   "source": [
    "## Dataset structure on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a332f359"
   },
   "source": [
    "\n",
    "The `IAM` dataset is downloaded as zip file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6c44266"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.metadata.iam import DL_DATA_DIRNAME\n",
    "\n",
    "\n",
    "iam_dir = DL_DATA_DIRNAME\n",
    "!ls {iam_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8463c2d1"
   },
   "source": [
    "Inside that zip file are the following folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "536924f7"
   },
   "outputs": [],
   "source": [
    "iamdb = iam_dir / \"iamdb\"\n",
    "\n",
    "!du -h {iamdb}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64240b05"
   },
   "source": [
    "There are >3000 files, almost all of which are `.xml` or `.jpg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eea605de"
   },
   "outputs": [],
   "source": [
    "!find {iamdb} | grep \"\\.jpg$\\|\\.xml$\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e53b475c"
   },
   "source": [
    "And they are equal in number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "514bfd92"
   },
   "outputs": [],
   "source": [
    "!find {iamdb}/xml | grep \"\\.xml$\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73309c2d"
   },
   "outputs": [],
   "source": [
    "!find {iamdb}/forms | grep \"\\.jpg$\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7dbaff6"
   },
   "source": [
    "Where there are many small files in equal number, there are inputs and targets.\n",
    "\n",
    "And indeed, an individual \"datapoint\" in `IAM` is a \"form\", because the humans whose hands wrote the data were writing on \"forms\", as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "945d5e3a"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "form_fn, = !find {iamdb}/forms | grep \".jpg$\" | sort | head -n 1\n",
    "\n",
    "print(form_fn)\n",
    "Image(filename=form_fn, width=\"360\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9e9e384"
   },
   "source": [
    "And the `xml` files indeed contain the targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6add5c5a"
   },
   "outputs": [],
   "source": [
    "xml_fn, = !find {iamdb}/xml | grep \"\\.xml$\" | sort | head -n 1\n",
    "\n",
    "!cat {xml_fn} | grep -A 100 \"handwritten-part\" | grep \"<word\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64d3389c"
   },
   "source": [
    "But they also contain the metadata required to convert images of entire forms into more useful images, e.g. of lines or paragraphs of handwritten text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b063e7bb"
   },
   "outputs": [],
   "source": [
    "xml_fn, = !find {iamdb}/xml | grep \"\\.xml$\" | head -n 1\n",
    "\n",
    "!cat {xml_fn} | grep -A 25 \"handwritten-part\" | grep -A 5 \"<word\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd51b664"
   },
   "source": [
    "The `ascii` folder has metadata in `.txt` files in the ASCII format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b745a594"
   },
   "source": [
    "There's a handful of other files full of metadata -- e.g. the training, validation, and test splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84c21f75"
   },
   "outputs": [],
   "source": [
    "!find {iamdb} | grep \"\\\\.txt$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a831c393"
   },
   "source": [
    "The `ascii` folder has metadata in `.txt` files in the ASCII format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dfa7b27"
   },
   "outputs": [],
   "source": [
    "!ls -lh {iamdb}/ascii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9rJgvgktg1h"
   },
   "source": [
    "## Extracting paragraphs from raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXS1xs8Luy3Z"
   },
   "source": [
    "So from images of entire forms\n",
    "and XML positiona and label metadata,\n",
    "we need to extract cropped images\n",
    "of paragraphs and string labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fa0tgKLtu_8"
   },
   "outputs": [],
   "source": [
    "import text_recognizer.util as util\n",
    "\n",
    "form_id = \"g01-031\"\n",
    "fn = iam.form_filenames_by_id[form_id]\n",
    "\n",
    "print(fn)\n",
    "Image(filename=fn, width=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMkPvR5guy3Z"
   },
   "source": [
    "This is handled by a utility function, `get_paragraph_crops_and_labels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUiwbprWtq4f"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam_paragraphs import get_paragraph_crops_and_labels\n",
    "\n",
    "p_crops, p_labels = get_paragraph_crops_and_labels(iam, split=\"val\")\n",
    "\n",
    "print(p_labels[form_id])\n",
    "p_crops[form_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ns39ag8YvfYB"
   },
   "source": [
    "Loosely: we calculate paragraph regions\n",
    "by joining over the line regions.\n",
    "\n",
    "We pull line regions from the XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNVYKFp0uy3a"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam import _get_line_regions_from_xml_file\n",
    "\n",
    "_get_line_regions_from_xml_file??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSggKKjMuy3a"
   },
   "source": [
    "We resize them so they take up less disk space.\n",
    "\n",
    "We invert them because many NNs work better\n",
    "with positive features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sz377cIs5LtO"
   },
   "source": [
    "## Structuring into a PyTorch dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqC0jTKm5KQa"
   },
   "source": [
    "Lastly, we convert to something we can use with PyTorch and `torchvision`: a PyTorch `Dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1y4jUPe5-bR"
   },
   "source": [
    "A basic `Dataset` just allows us to index into multiple sources of data\n",
    "(e.g. the inputs and the targets) at the same time.\n",
    "\n",
    "We want our targets to be `Tensor`s,\n",
    "so we convert the strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J67-NACg3biT"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.data.util import convert_strings_to_labels\n",
    "from text_recognizer.data import IAMParagraphs\n",
    "\n",
    "iam_paragraphs = IAMParagraphs()\n",
    "\n",
    "tensor_labels = convert_strings_to_labels(\n",
    "    strings=p_labels,\n",
    "    mapping=iam_paragraphs.inverse_mapping,\n",
    "    length=iam_paragraphs.output_dims[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBkisYBy6OeZ"
   },
   "source": [
    "We do eventually want `Tensor`s out of our images,\n",
    "but we want our `DataLoader` to do stuff during forward pass,\n",
    "make use of CPUs,\n",
    "so we leave our inputs as a list of `Image`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuCODqWA5ZPF"
   },
   "outputs": [],
   "source": [
    "list_crops = list(p_crops.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUGNL7-F6cHq"
   },
   "source": [
    "We combine them together with our `BaseDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMPgGl4a3BUL"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "from text_recognizer.data.util import BaseDataset\n",
    "\n",
    "\n",
    "dataset = BaseDataset(list_crops, tensor_labels)\n",
    "\n",
    "im, label = dataset[0]\n",
    "wandb.Image(im).image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_krdrSIwO6B"
   },
   "source": [
    "## Synthesizing handwritten paragraphs from handwritten lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCYEEevfwVAf"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam_synthetic_paragraphs import IAMSyntheticParagraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tsEMCLsv_39"
   },
   "source": [
    "# FSDL Handwriting Dataset: From images to an annotated dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6wZUgndGwPb"
   },
   "source": [
    "Above, we relied on an existing dataset,\n",
    "already nicely formatted with images and their annotations.\n",
    "\n",
    "But data does not come to us like this.\n",
    "\n",
    "Inputs collected from the world somehow,\n",
    "and annotations are often collected from humans.\n",
    "\n",
    "Let's walk through how that's done.\n",
    "\n",
    "We'll use a dataset of text prompts\n",
    "and handwritten responses collected during the 2019 edition of FSDL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFAGLvKtR4IX"
   },
   "source": [
    "## Handling Data with AWS S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3JwClhTHBvT"
   },
   "source": [
    "We begin a few steps after the beginning:\n",
    "data has been collected from humans who were tasked with\n",
    "writing out text prompts by hand on paper forms,\n",
    "and those forms were scanned and digitized.\n",
    "\n",
    "The digitized forms were placed in storage on Amazon Web Services'\n",
    "Simple Storage Service, aka S3,\n",
    "which is a form of object storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nrag5zsUHi_f"
   },
   "source": [
    "They are publicly accessible, so we can view them directly by inputting a URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrT3XzkdHnb-"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "idx = 117\n",
    "img_url = f\"https://fsdl-public-assets.s3.us-west-2.amazonaws.com/fsdl_handwriting_20190302/page-{str(idx).zfill(3)}.jpg\"\n",
    "print(img_url)\n",
    "Image(url=img_url, width=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kpoo_N8YHghg"
   },
   "source": [
    "For programmatic access,\n",
    "we use\n",
    "[`boto3`](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html),\n",
    "the Python SDK for AWS.\n",
    "\n",
    "It is named after the Portuguese term for\n",
    "[river dolphins native to the Amazon river](https://en.wikipedia.org/wiki/Boto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7Mvx6wMirga"
   },
   "outputs": [],
   "source": [
    "import boto3  # boto3: high-level API\n",
    "from botocore import UNSIGNED  # botocore: lower-level API and components\n",
    "from botocore.config import Config\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLCvaWgfJpi-"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.metadata.shared import DATA_DIRNAME\n",
    "\n",
    "\n",
    "FSDL_RAW_DATA_DIRNAME = DATA_DIRNAME / \"raw\" / \"fsdl_handwriting\"\n",
    "FSDL_DL_DATA_DIRNAME = DATA_DIRNAME / \"downloaded\" / \"fsdl_handwriting\"/ \"pages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSn7nckqi4KT",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p {FSDL_DL_DATA_DIRNAME}\n",
    "\n",
    "s3.download_file(\"fsdl-public-assets\", \"fsdl_handwriting_20190302/page-001.jpg\", f\"{FSDL_DL_DATA_DIRNAME}/page-001.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRAhWxmGjOFB"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=f\"{FSDL_DL_DATA_DIRNAME}/page-001.jpg\", height=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AkQCxQkkvWu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "s3_resource = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "def download_s3_folder(bucket_name, s3_folder, local_dir=None):\n",
    "    \"\"\"Download the contents of a folder on S3, recursively.\n",
    "\n",
    "    Args:\n",
    "        bucket_name: the name of the s3 bucket\n",
    "        s3_folder: the folder path in the s3 bucket\n",
    "        local_dir: a relative or absolute directory path in the local file system\n",
    "    \"\"\"\n",
    "    # from https://stackoverflow.com/questions/49772151/download-a-folder-from-s3-using-boto3\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "    for obj in bucket.objects.filter(Prefix=s3_folder):\n",
    "        target = obj.key if local_dir is None \\\n",
    "            else os.path.join(local_dir, os.path.relpath(obj.key, s3_folder))\n",
    "        if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(os.path.dirname(target))\n",
    "        if obj.key[-1] == '/':\n",
    "            continue\n",
    "        bucket.download_file(obj.key, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhrbyDz4k7FK"
   },
   "outputs": [],
   "source": [
    "download_s3_folder(\"fsdl-public-assets\", \"fsdl_handwriting_20190302\", FSDL_DL_DATA_DIRNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yB0nBexmGbw"
   },
   "outputs": [],
   "source": [
    "!find {FSDL_DL_DATA_DIRNAME} | head -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBomSqF9HITx"
   },
   "outputs": [],
   "source": [
    "%%writefile {FSDL_RAW_DATA_DIRNAME}/manifest.csv\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IV7rY7k8fPP-"
   },
   "outputs": [],
   "source": [
    "s3_bucket_name = \"fsdl-public-assets\"\n",
    "s3_directory_path = \"fsdl_handwriting_20190302/\"\n",
    "s3_url = f\"https://{s3_bucket_name}.s3.us-west-2.amazonaws.com/{s3_directory_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0O6XcenEmOF"
   },
   "outputs": [],
   "source": [
    "!find {FSDL_DL_DATA_DIRNAME} | grep \"page-.*.jpg$\" | sed \"s\\\\{FSDL_DL_DATA_DIRNAME}/\\\\{s3_url}\\\\\"| sort >> {FSDL_RAW_DATA_DIRNAME}/manifest.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_3SeV2MHRoM"
   },
   "outputs": [],
   "source": [
    "!cat {FSDL_RAW_DATA_DIRNAME}/manifest.csv | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl0tfqXuR6Sx"
   },
   "source": [
    "## Annotation with Label Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PodS_Xlvl2R"
   },
   "source": [
    "### Configuring and connecting to the web server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZZPWLP6X1AS"
   },
   "outputs": [],
   "source": [
    "username = \"fsdl@localhost\"\n",
    "password = \"pancakes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSB8m7ftXWxJ"
   },
   "outputs": [],
   "source": [
    "%env DJANGO_SETTINGS_MODULE=data.raw.fsdl_handwriting.labelstudio_settings\n",
    "%env LABEL_STUDIO_USERNAME={username}\n",
    "%env LABEL_STUDIO_PASSWORD={password}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nr6EFk_suy3d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "from pyngrok import ngrok\n",
    "\n",
    "\n",
    "if not os.path.exists(ngrok.conf.DEFAULT_NGROK_CONFIG_PATH):\n",
    "    print(\"Enter your ngrok auth token, which can be copied from https://dashboard.ngrok.com/auth\")\n",
    "    ngrok.conf.get_default().auth_token = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhDcoGI9Ry_W",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LABEL_STUDIO_PORT = 8081\n",
    "\n",
    "https_tunnel = ngrok.connect(LABEL_STUDIO_PORT, bind_tls=True)\n",
    "print(https_tunnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23gsKGAHuy3d"
   },
   "source": [
    "We'll briefly install `label-studio` here.\n",
    "\n",
    "Not compatible with the rest of our environment,\n",
    "so we'll clean it up at the end\n",
    "(if running locally).\n",
    "\n",
    "Intended to be run inside a Docker container\n",
    "or a special-purpose server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQO1ewncuy3d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -qqq label-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-OolSabuy3e"
   },
   "outputs": [],
   "source": [
    "%%script bash --bg --proc label_studio_proc\n",
    "\n",
    "label-studio start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7laZW302jgc"
   },
   "source": [
    "Give it about 30 seconds to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Py6cwJAE1yI7"
   },
   "outputs": [],
   "source": [
    "print(https_tunnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzWzIKtZuy3e"
   },
   "source": [
    "## Label Studio Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4460l_Shuy3e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "in_colab = \"google.colab\" in sys.modules\n",
    "done_with_label_studio = True\n",
    "\n",
    "if done_with_label_studio:\n",
    "    !pkill -P {label_studio_proc.pid}\n",
    "    if not in_colab:\n",
    "        !make pip-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09zvo8xMkNVO"
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMScXTVXkOrk"
   },
   "source": [
    "### ðŸŒŸ Do some data labelling yourself.\n",
    "\n",
    "Label a handful of pages.\n",
    "Notice the edge cases.\n",
    "Incorporate them into labeling instructions.\n",
    "\n",
    "Interesting ones: #24, #35, #97."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-N27-Lu8NtfG"
   },
   "source": [
    "### ðŸŒŸðŸŒŸ Hook up S3 directly to Label Studio.\n",
    "\n",
    "Create an AWS account. Get your Access Key ID.\n",
    "\n",
    "Guide [here](https://labelstud.io/guide/storage.html), but because public access, can start\n",
    "[here](https://labelstud.io/guide/storage.html#Set-up-connection-in-the-Label-Studio-UI).\n",
    "\n",
    "Do not need pre-signed URLs or a Session Token. Our region is us-west-2.\n",
    "\n",
    "Bucket name and bucket prefix are above. Files are all `.jpg`."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab06_data.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
